//
//  ASLInterpreterViewController.swift
//  ASLInterpreter
//
//  Created by Daniel Gallego Peralta on 28/3/21.
//  Copyright (c) 2021 ___ORGANIZATIONNAME___. All rights reserved.
//
//  This file was generated by the Clean Swift Xcode Templates so
//  you can apply clean architecture to your iOS and Mac projects,
//  see http://clean-swift.com
//

import UIKit
import Vision
import AVFoundation

protocol ASLInterpreterDisplayLogic: class {
    func displayDetectedWord(viewModel: ASLInterpreter.DetectedWord.ViewModel)
}

class ASLInterpreterViewController: UIViewController, ASLInterpreterDisplayLogic {
    var interactor: ASLInterpreterBusinessLogic?
    var router: (NSObjectProtocol & ASLInterpreterRoutingLogic & ASLInterpreterDataPassing)?
    
    //MARK: - Instance properties
    
    private let handBoundingBox = BoundingBoxView()
    private var handPoseRequest: VNDetectHumanHandPoseRequest!
    private var gestureProcessor: GestureDataSource = HandGestureProcessor()
    
    var aslView: ASLInterpreterView! {
        guard isViewLoaded else {
            return nil
        }
        return (view as! ASLInterpreterView)
    }
    
    // MARK: Object lifecycle
    
    override init(nibName nibNameOrNil: String?, bundle nibBundleOrNil: Bundle?) {
        super.init(nibName: nibNameOrNil, bundle: nibBundleOrNil)
        setup()
    }
    
    required init?(coder aDecoder: NSCoder) {
        super.init(coder: aDecoder)
        setup()
    }
    
    // MARK: Setup
    
    private func setup() {
        let viewController = self
        let interactor = ASLInterpreterInteractor()
        let presenter = ASLInterpreterPresenter()
        let router = ASLInterpreterRouter()
        viewController.interactor = interactor
        viewController.router = router
        interactor.presenter = presenter
        presenter.viewController = viewController
        router.viewController = viewController
        router.dataStore = interactor
    }
    
    // MARK: Routing
    
    override func prepare(for segue: UIStoryboardSegue, sender: Any?) {
        if let scene = segue.identifier {
            let selector = NSSelectorFromString("routeTo\(scene)WithSegue:")
            if let router = router, router.responds(to: selector) {
                router.perform(selector, with: segue)
            }
        }
    }
    
    // MARK: View lifecycle
    
    override func viewDidLoad() {
        super.viewDidLoad()
        setupView()
        
        gestureProcessor.didChangeStateClosure = { [unowned self] state in
            if state == State.apart {
                self.interactor?.finishedWord()
            }
        }
    }
    
    override func loadView() {
        view = ASLInterpreterView()
    }
    
    override func viewWillAppear(_ animated: Bool) {
        super.viewWillAppear(animated)
    }
    
    override func viewDidAppear(_ animated: Bool) {
        super.viewDidAppear(animated)
        handPoseRequest = VNDetectHumanHandPoseRequest()
        handPoseRequest.maximumHandCount = 2
    }
    
    func setupView() {
        handBoundingBox.borderColor = #colorLiteral(red: 1, green: 0.5763723254, blue: 0, alpha: 1)
        handBoundingBox.borderWidth = 2
        handBoundingBox.borderCornerRadius = 4
        handBoundingBox.borderCornerSize = 0
        handBoundingBox.backgroundOpacity = 0.45
        handBoundingBox.isHidden = true
        view.addSubview(handBoundingBox)
    }
    
    // MARK: Utils
    
    func updateBoundingBox(_ boundingBox: BoundingBoxView, withViewRect rect: CGRect?, visionRect: CGRect) {
        DispatchQueue.main.async {
            boundingBox.frame = rect ?? .zero
            boundingBox.visionRect = visionRect
            if rect == nil {
                boundingBox.perform(transition: .fadeOut, duration: 0.1)
            } else {
                boundingBox.perform(transition: .fadeIn, duration: 0.1)
            }
        }
    }
    
    func showError(_ msg: String) {
        self.view.makeToast(msg)
    }
}

//MARK: - CameraViewControllerDelegate

extension ASLInterpreterViewController: CameraViewControllerDelegate {
    
    func cameraViewController(_ controller: CameraViewController, didReceiveBuffer buffer: CMSampleBuffer, orientation: CGImagePropertyOrientation) {
        
        do {
            try self.checkObservations(controller,
                                       buffer: buffer,
                                       orientation: orientation)
        } catch {
            showError("error check observations")
        }
    }
    
}

//MARK - ASL Interpreter

extension ASLInterpreterViewController {
    
    func checkObservations(_ controller: CameraViewController, buffer: CMSampleBuffer, orientation: CGImagePropertyOrientation) throws {
        let visionHandler = VNImageRequestHandler(cmSampleBuffer: buffer, orientation: orientation, options: [:])
        try visionHandler.perform([handPoseRequest])
        
        if let observations = handPoseRequest.results  {
            let filteredResults = observations.filter { $0.confidence > ASLConfiguration.shared.handDetectionMinConfidence }
            
            guard filteredResults.isNotEmpty else {
                updateBoundingBox(handBoundingBox, withViewRect: nil, visionRect: CGRect.null)
                return
            }
            
            switch ASLConfiguration.shared.workingMode {
            case .words:
                let (rightHand, leftHand) = VisionUtils.filterBothHands(filteredResults)
                let state = gestureProcessor.getCurrentState()
                
                ///if not both hands only hand detector
                guard let _ = leftHand else {
                    if state == .possiblePinch || state == .pinched || state == .possibleApart {
                        performHandDetector(controller, filteredResults: [rightHand])
                    }
                    return
                }
                
                let handDetectorObservation = ASLConfiguration.shared.handCase == .right ? rightHand : leftHand
                let pinchDetectorObservation = ASLConfiguration.shared.handCase == .right ? leftHand : rightHand
                
                if state == .possiblePinch || state == .pinched || state == .possibleApart {
                    performHandDetector(controller, filteredResults: [handDetectorObservation!])
                }

                performPinchDetector(controller, filteredResults: [pinchDetectorObservation!])
                
            default:
                performHandDetector(controller, filteredResults: filteredResults)
            }
        } else {
            updateBoundingBox(handBoundingBox, withViewRect: nil, visionRect: CGRect.null)
        }
    }
    
    func performPinchDetector(_ controller: CameraViewController, filteredResults: [VNHumanHandPoseObservation]) {
        guard let rightHand = VisionUtils.filterObservation(by: .right, observations: filteredResults) else {
            print("norighthand")
            return
        }
        
        guard let middlePoints = try? rightHand.recognizedPoints(.thumb),
              let indexFingerPoints = try? rightHand.recognizedPoints(.indexFinger),
              let middleTipPoint = middlePoints[.thumbTip],
              let indexTipPoint = indexFingerPoints[.indexTip] else {
            return
        }
            
        let minConfidenceFinger: VNConfidence = 0.3
        guard middleTipPoint.confidence > minConfidenceFinger && indexTipPoint.confidence > minConfidenceFinger else {
            return
        }
        
        let thumbTip = middleTipPoint.location.applying(.verticalFlip)
        let indexTip = indexTipPoint.location.applying(.verticalFlip)
            
       
        let thumbTipLayer = controller.viewPointForVisionPoint(thumbTip)
        let indexTipLayer = controller.viewPointForVisionPoint(indexTip)
        gestureProcessor.newPoints(thumbTip: thumbTipLayer, indexTip: indexTipLayer)
    }
    
    func performHandDetector(_ controller: CameraViewController, filteredResults: [VNHumanHandPoseObservation]) {
        var rect: CGRect?
        var visionRect = CGRect.null
        if let handObservation = VisionUtils.filterCaseHand(filteredResults) {
            visionRect = VisionUtils.handBoundingBox(for: handObservation)
            
            //invalid negative coordinates
            if visionRect.origin.x < 0 || visionRect.origin.y < 0 {
                return
            }
            
            DispatchQueue.main.async {
                rect = controller.viewRectForVisionRect(visionRect)
                self.updateBoundingBox(self.handBoundingBox, withViewRect: rect, visionRect: visionRect)
            }
            
            //extract features point and asl
            performASLExtractedFeaturesPoint(controller, observation: handObservation)
        }
    }
    
    func performASLExtractedFeaturesPoint(_ controller: CameraViewController, observation: VNHumanHandPoseObservation) {
        guard let hand = VisionProcessImage.sharedInstance.processObservations(observation), let features = hand.extractIfValidFeatures(flipX: ASLConfiguration.shared.handCase == ASLConfiguration.HandCase.left) else {
            print("failed to extract hand features")
            return
        }
        
        print(features.description)
        
        
        
        if let multiArrayBuffer = try? MLMultiArray(features) {
            let labelProbability = ASLConfiguration.shared.prediction(multiArrayBuffer: multiArrayBuffer)
            let top3 = labelProbability.sorted {
                return $0.value > $1.value
            }.prefix(3)
            
            let descriptionTop3 = top3.map { observation in
                String(format: "%@ %.1f%%", observation.key, observation.value * 100)}
            DispatchQueue.main.async {
                if ASLConfiguration.shared.isDebugMode {
                    self.aslView.labelResults.text = descriptionTop3.joined(separator: "\n")
                }
            }
            
            if let betterPrediction = top3.first, betterPrediction.value > Double(ASLConfiguration.shared.letterDetectionMinConfidence) {
                interactor?.topPredictionLetter(betterPrediction.key)
            }
        }
    }
}

//MARK: - Input

extension ASLInterpreterViewController {
    func displayDetectedWord(viewModel: ASLInterpreter.DetectedWord.ViewModel){
        aslView.labelDetectedWord.text = viewModel.letter
    }
}
